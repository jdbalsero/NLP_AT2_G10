{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test calling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking a woman out on a date can be nerve-wracking, but with some tips and advice, you can increase your chances of getting a positive response. Here's a step-by-step guide on how to ask a woman out for a date:\n",
      "\n",
      "**Before you ask:**\n",
      "\n",
      "1. **Get to know her**: Try to have a conversation with her and get to know her interests, hobbies, and values. This will help you find common ground and make the ask more personal.\n",
      "2. **Make sure you're interested**: Ensure that you're genuinely interested in getting to know her better and that it's not just a casual ask.\n",
      "3. **Be respectful**: Remember that she's a person with her own thoughts, feelings, and boundaries. Be respectful of her time and decision.\n",
      "\n",
      "**The ask:**\n",
      "\n",
      "1. **Choose the right time and place**: Find a private and comfortable setting where you both feel at ease. Avoid asking her out in front of a large group or in a noisy environment.\n",
      "2. **Be confident and genuine**: Take a deep breath, be yourself, and speak clearly. Avoid using cheesy pickup lines or trying to be someone you're not.\n",
      "3. **Be specific**: Instead of asking her out on a generic \"hangout,\" suggest a specific activity or date idea that you think she'll enjoy.\n",
      "4. **Use positive body language**: Maintain eye contact, smile, and use open and relaxed body language.\n",
      "5. **Be clear and direct**: Say something like, \"I've really enjoyed getting to know you, and I was wondering if you'd like to go out on a date with me?\"\n",
      "\n",
      "**Example ask:**\n",
      "\n",
      "\"Hey [her name], I've really enjoyed talking to you and getting to know you. I was thinking it would be great to grab coffee or go for a walk sometime. Would you like to join me for [specific activity] on [specific day]?\"\n",
      "\n",
      "**After the ask:**\n",
      "\n",
      "1. **Be prepared for any response**: She might say yes, no, or maybe. Be respectful of her decision and don't take it personally if she declines.\n",
      "2. **Follow up**: If she says yes, make sure to follow up and confirm the details of the date. If she says no, thank her for her time and wish her well.\n",
      "\n",
      "**Additional tips:**\n",
      "\n",
      "1. **Be respectful of her boundaries**: If she says no or doesn't seem interested, don't push the issue.\n",
      "2. **Don't overthink it**: Try not to overanalyze the situation or worry too much about the outcome.\n",
      "3. **Be yourself**: Authenticity is key when asking someone out. Be true to yourself and your interests.\n",
      "\n",
      "Remember, asking someone out is a normal part of social interaction, and it's okay to take risks. Good luck!"
     ]
    }
   ],
   "source": [
    "from groq import Client\n",
    "from os import getenv\n",
    "\n",
    "client = Client(\n",
    "    api_key = getenv('GROQ_API_KEY')\n",
    ")\n",
    "user_prompt = 'how to ask a woman out for a date?'\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    # mandatory parameters\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'system',\n",
    "            'content' : 'you are a helpful assistant'\n",
    "        },\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : user_prompt\n",
    "        }\n",
    "    ],\n",
    "    model = 'llama-3.3-70b-versatile',\n",
    "    # optional para meters\n",
    "    # lower values of temperature are related to less randomness\n",
    "    temperature = 0.8,\n",
    "    # maximun number of tokens to generate\n",
    "    max_completion_tokens = 600,\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop = None,\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream = False\n",
    "    \n",
    ")\n",
    "print(response.choices[0].message.content, end = \"\")\n",
    "# for streaming = True\n",
    "# for chunk in response:\n",
    "#     print(chunk.choices[0].delta.content, end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what how to add memory to the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user question:\n",
      "how to bake brownies\n",
      "------------------------------------------------------------\n",
      "Baking brownies can be a delightful experience. Here's a simple recipe to get you started:\n",
      "\n",
      "**Classic Fudgy Brownies Recipe**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 and 1/2 sticks of unsalted butter (12 tablespoons), plus more for greasing the pan\n",
      "* 2 cups of sugar\n",
      "* 4 large eggs\n",
      "* 1/2 cup of unsweetened cocoa powder\n",
      "* 1 teaspoon of vanilla extract\n",
      "* 1/4 teaspoon of salt\n",
      "* 1 and 1/4 cups of all-purpose flour\n",
      "* 1 cup of semi-sweet chocolate chips\n",
      "* Optional: nuts, espresso powder, or other mix-ins of your choice\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. **Preheat your oven**: Set your oven to 350째F (180째C). Make sure to adjust the oven rack to the middle position to ensure even baking.\n",
      "2. **Prepare the pan**: Grease an 8-inch square baking pan with butter and line it with parchment paper. Leave some overhang on the sides for easy removal.\n",
      "3. **Melt the butter and sugar**: In a medium saucepan, melt the butter and sugar over low heat, stirring occasionally. Bring the mixture to a simmer and cook for about 5 minutes, or until the sugar has dissolved.\n",
      "4. **Remove from heat and add cocoa powder**: Remove the saucepan from the heat and stir in the cocoa powder until it's well combined.\n",
      "5. **Let it cool**: Let the mixture cool slightly, about 5-10 minutes. This is important to prevent the eggs from scrambling when you add them.\n",
      "6. **Add eggs one at a time**: Stir in the eggs one at a time, making sure each egg is fully incorporated before adding the next.\n",
      "7. **Add vanilla extract and salt**: Stir in the vanilla extract and salt.\n",
      "8. **Add flour**: Add the flour and stir until just combined, being careful not to overmix.\n",
      "9. **Stir in chocolate chips**: Stir in the chocolate chips and any optional mix-ins (like nuts or espresso powder).\n",
      "10. **Pour into the prepared pan**: Pour the batter into the prepared baking pan and smooth the top.\n",
      "11. **Bake**: Bake for 25-30 minutes or until a toothpick inserted into the center comes out with a few moist crumbs attached.\n",
      "12. **Let it cool**: Remove the brownies from the oven and let them cool completely in the pan.\n",
      "13. **Cut and serve**: Once cooled, lift the brownies out of the pan using the parchment paper and cut them into squares. Serve and enjoy!\n",
      "\n",
      "**Tips and Variations:**\n",
      "\n",
      "* For a chewier texture, bake for 23-25 minutes. For a firmer texture, bake for 30-35 minutes.\n",
      "* Use high-quality cocoa powder for the best flavor.\n",
      "* Add-ins like nuts, espresso powder, or dried fruit can enhance the flavor and texture.\n",
      "* If you want\n",
      "------------------------------------------------------------\n",
      "user question:\n",
      "what adjustments should I make to create a healthier version?\n",
      "------------------------------------------------------------\n",
      "To create a healthier version of brownies, you can make the following adjustments:\n",
      "\n",
      "1. **Reduce sugar**: Decrease the amount of sugar to 1 cup or even less, depending on your taste preference. You can also try using natural sweeteners like honey, maple syrup, or coconut sugar.\n",
      "2. **Use dark chocolate**: Dark chocolate contains more antioxidants and less sugar than milk chocolate. Look for dark chocolate with at least 70% cocoa solids.\n",
      "3. **Choose healthier fats**: Replace butter with healthier fats like coconut oil, avocado oil, or olive oil. You can also use applesauce or mashed banana to reduce the amount of oil needed.\n",
      "4. **Increase fiber**: Add some fiber-rich ingredients like oats, whole wheat flour, or chia seeds to increase the nutritional value of your brownies.\n",
      "5. **Use egg substitutes**: If you're looking for a vegan or lower-cholesterol option, you can replace eggs with flaxseed, chia seeds, or mashed banana.\n",
      "6. **Reduce flour**: Use almond flour, coconut flour, or oat flour to reduce the amount of refined flour in your brownies.\n",
      "7. **Add nuts and seeds**: Nuts and seeds like walnuts, almonds, and chia seeds are rich in healthy fats, protein, and fiber.\n",
      "8. **Use natural sweetener alternatives**: Try using stevia, monk fruit sweetener, or erythritol to reduce the sugar content of your brownies.\n",
      "\n",
      "Here's an example of how you can modify the original recipe to create a healthier version:\n",
      "\n",
      "**Healthier Brownies Recipe**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1/2 cup coconut oil\n",
      "* 1/2 cup honey or maple syrup\n",
      "* 2 large eggs or egg substitutes\n",
      "* 1/2 cup unsweetened cocoa powder\n",
      "* 1 teaspoon vanilla extract\n",
      "* 1/4 teaspoon salt\n",
      "* 1 cup whole wheat flour\n",
      "* 1/2 cup rolled oats\n",
      "* 1/2 cup chopped nuts (walnuts or almonds)\n",
      "* 1/4 cup dark chocolate chips (at least 70% cocoa solids)\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 350째F (180째C).\n",
      "2. Mix the coconut oil, honey or maple syrup, eggs, and vanilla extract in a large bowl.\n",
      "3. Add the cocoa powder, salt, whole wheat flour, and rolled oats to the bowl and mix until well combined.\n",
      "4. Stir in the chopped nuts and dark chocolate chips.\n",
      "5. Pour the batter into a greased 8-inch square baking pan and smooth the top.\n",
      "6. Bake for 25-30 minutes or until a toothpick inserted into the center comes out with a few moist crumbs attached.\n",
      "7. Let the brownies cool completely in the pan before cutting and serving.\n",
      "\n",
      "**Nutritional comparison:**\n",
      "\n",
      "Original recipe (per serving):\n",
      "\n",
      "* Calories: 220\n",
      "* Sugar: 20g\n",
      "* Fat: 12g\n",
      "* Saturated\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\n",
    "        'role' : 'system',\n",
    "        'content' : 'you are a helpful AI assistant'\n",
    "    }\n",
    "]\n",
    "def chat_with_memory(\n",
    "    user_prompt : str\n",
    "):\n",
    "    # adding the user input to the conversation history\n",
    "    chat_history.append(\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : user_prompt\n",
    "        }\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        messages = chat_history,\n",
    "        model='llama-3.3-70b-versatile',\n",
    "        temperature=0.8,\n",
    "        max_completion_tokens=600,\n",
    "        stop=None,\n",
    "        stream=False\n",
    "    )\n",
    "    ai_response = response.choices[0].message.content\n",
    "    # addding ai response to the conversation history\n",
    "    chat_history.append(\n",
    "        {\n",
    "            'role' : 'assistant',\n",
    "            'content' : ai_response\n",
    "        }\n",
    "    )\n",
    "    return ai_response\n",
    "\n",
    "questions = [\n",
    "    'how to bake brownies',\n",
    "    'what adjustments should I make to create a healthier version?',\n",
    "]\n",
    "for q in questions:\n",
    "    print(f\"user question:\\n{q}\")\n",
    "    print('-'*60)\n",
    "    print(chat_with_memory(q))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a legal disclaimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer, category\n\u001b[1;32m     63\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan I sue my employer for wrongful termination?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 64\u001b[0m response, category \u001b[38;5;241m=\u001b[39m \u001b[43mchat_with_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m, in \u001b[0;36mchat_with_memory\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     43\u001b[0m ai_reply \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     json_format_response \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mai_reply\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     answer \u001b[38;5;241m=\u001b[39m json_format_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIt was not possible to process the prompt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m     category \u001b[38;5;241m=\u001b[39m json_format_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# setting the system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant. \n",
    "Your task is to provide a response to the user's question and classify whether the topic falls into:\n",
    "- Legal\n",
    "- Financial\n",
    "- General (if it's neither legal nor financial)\n",
    "\n",
    "Return a JSON object with:\n",
    "- 'response': Your answer to the user.\n",
    "- 'category': One of ['legal', 'financial', 'general'].\n",
    "\"\"\"\n",
    "# setting the disclaimer message\n",
    "DISCLAIMER_MESSAGE = (\n",
    "    \"\\n\\n**Disclaimer:** Be mindful that this is an AI assistant. \"\n",
    "    \"Please consult with a professional before proceeding.\"\n",
    ")\n",
    "# initialize the chat history\n",
    "messages = [\n",
    "        {\n",
    "            'role' : 'system',\n",
    "            'content' : SYSTEM_PROMPT\n",
    "        }\n",
    "    ]\n",
    "def chat_with_memory(\n",
    "    user_prompt : str\n",
    "):\n",
    "    # add prompt to the chat history\n",
    "    messages.append(\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : user_prompt\n",
    "        }\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.8,\n",
    "        max_completion_tokens=600,\n",
    "        stop=None,\n",
    "        stream=False\n",
    "    )\n",
    "    ai_reply = response.choices[0].message.content\n",
    "    try:\n",
    "        json_format_response = json.load(ai_reply)\n",
    "        answer = json_format_response.get('response', 'It was not possible to process the prompt')\n",
    "        category = json_format_response.get('category', 'general').lower()\n",
    "    except json.JSONDecodeError:\n",
    "        answer = ai_reply\n",
    "        category = 'general'\n",
    "    \n",
    "    if category in ['legal', 'financial']:\n",
    "        answer += DISCLAIMER_MESSAGE\n",
    "    # update the chat history\n",
    "    messages.append(\n",
    "        {\n",
    "            'role' : 'assistant',\n",
    "            'content' : answer\n",
    "        }\n",
    "    )\n",
    "    return answer, category\n",
    "    \n",
    "user_prompt = \"Can I sue my employer for wrongful termination?\"\n",
    "response, category = chat_with_memory(user_prompt)\n",
    "print(f\"Category: {category}\\nResponse:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
