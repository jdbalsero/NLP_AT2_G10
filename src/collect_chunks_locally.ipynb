{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57decfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to your ChromaDB host\n",
    "client = chromadb.HttpClient(host=\"170.64.231.135\", port=8000)\n",
    "\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d299f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "{\"error\":\"ValueError('Collection ghg_collection does not exist.')\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/chromadb/api/fastapi.py:652\u001b[39m, in \u001b[36mraise_chroma_error\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m     \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 500 Server Error: Internal Server Error for url: http://170.64.231.135:8000/api/v1/collections/ghg_collection?tenant=default_tenant&database=default_database",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mghg_collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Fetch all documents (adjust limit if needed)\u001b[39;00m\n\u001b[32m      4\u001b[39m results = collection.get(include=[\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m], limit = \u001b[32m1000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/chromadb/api/client.py:218\u001b[39m, in \u001b[36mClient.get_collection\u001b[39m\u001b[34m(self, name, id, embedding_function, data_loader)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_collection\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m     data_loader: Optional[DataLoader[Loadable]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    217\u001b[39m ) -> Collection:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[39m, in \u001b[36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity < granularity:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/chromadb/api/fastapi.py:304\u001b[39m, in \u001b[36mFastAPI.get_collection\u001b[39m\u001b[34m(self, name, id, embedding_function, data_loader, tenant, database)\u001b[39m\n\u001b[32m    300\u001b[39m     _params[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m)\n\u001b[32m    301\u001b[39m resp = \u001b[38;5;28mself\u001b[39m._session.get(\n\u001b[32m    302\u001b[39m     \u001b[38;5;28mself\u001b[39m._api_url + \u001b[33m\"\u001b[39m\u001b[33m/collections/\u001b[39m\u001b[33m\"\u001b[39m + name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m), params=_params\n\u001b[32m    303\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[43mraise_chroma_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m resp_json = json.loads(resp.text)\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    307\u001b[39m     client=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m     name=resp_json[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     metadata=resp_json[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    313\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UTS/Applied_NLP/NLP_AT2_G10/.venv/lib/python3.11/site-packages/chromadb/api/fastapi.py:654\u001b[39m, in \u001b[36mraise_chroma_error\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    652\u001b[39m     resp.raise_for_status()\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError:\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m(resp.text))\n",
      "\u001b[31mException\u001b[39m: {\"error\":\"ValueError('Collection ghg_collection does not exist.')\"}"
     ]
    }
   ],
   "source": [
    "\n",
    "collection = client.get_collection(name=\"ghg_collection\")\n",
    "\n",
    "# Fetch all documents (adjust limit if needed)\n",
    "results = collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"], limit = 1000)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"document\": results[\"documents\"],\n",
    "    \"metadata\": results[\"metadatas\"],\n",
    "    \"embedding\": results[\"embeddings\"]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"ghg_chunks_export.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Exported to ghg_chunks_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b6f413c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>metadata</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Page 1:\\nMain Content: COMPENDIUM\\nOF GREENHOU...</td>\n",
       "      <td>{'chunk_number': 1, 'page_count': 898, 'source...</td>\n",
       "      <td>[0.07204415649175644, 0.051991917192935944, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.................................................</td>\n",
       "      <td>{'chunk_number': 10, 'page_count': 898, 'sourc...</td>\n",
       "      <td>[0.035045888274908066, 0.04470682516694069, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenhouse Gas Emissions Estimation and Invent...</td>\n",
       "      <td>{'chunk_number': 100, 'page_count': 898, 'sour...</td>\n",
       "      <td>[0.03205292671918869, 0.03343049809336662, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b Shires, T.M. Methane Emissions from the Natu...</td>\n",
       "      <td>{'chunk_number': 1000, 'page_count': 898, 'sou...</td>\n",
       "      <td>[0.023349491879343987, 0.019071441143751144, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101, September 2004). This equates to 0.015 to...</td>\n",
       "      <td>{'chunk_number': 1001, 'page_count': 898, 'sou...</td>\n",
       "      <td>[0.024319730699062347, -0.004943027161061764, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  Page 1:\\nMain Content: COMPENDIUM\\nOF GREENHOU...   \n",
       "1  .................................................   \n",
       "2  Greenhouse Gas Emissions Estimation and Invent...   \n",
       "3  b Shires, T.M. Methane Emissions from the Natu...   \n",
       "4  101, September 2004). This equates to 0.015 to...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'chunk_number': 1, 'page_count': 898, 'source...   \n",
       "1  {'chunk_number': 10, 'page_count': 898, 'sourc...   \n",
       "2  {'chunk_number': 100, 'page_count': 898, 'sour...   \n",
       "3  {'chunk_number': 1000, 'page_count': 898, 'sou...   \n",
       "4  {'chunk_number': 1001, 'page_count': 898, 'sou...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.07204415649175644, 0.051991917192935944, 0....  \n",
       "1  [0.035045888274908066, 0.04470682516694069, 0....  \n",
       "2  [0.03205292671918869, 0.03343049809336662, 0.0...  \n",
       "3  [0.023349491879343987, 0.019071441143751144, 0...  \n",
       "4  [0.024319730699062347, -0.004943027161061764, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chunk_text = pd.read_csv(\"ghg_chunks_export.csv\")\n",
    "\n",
    "\n",
    "chunk_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51f485c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Generated Q&A Pairs:\n",
      "\n",
      "Here are the Q&A pairs summarizing key insights, regulatory obligations, and challenges for companies:\n",
      "\n",
      "Q1: What is the primary purpose of the Compendium of Greenhouse Gas Emissions Methodologies for the Natural Gas and Oil Industry?\n",
      "A1: The compendium provides a comprehensive guide for companies in the natural gas and oil industry to measure and report their greenhouse gas (GHG) emissions.\n",
      "\n",
      "Q2: Who developed the compendium, and who sponsored the work?\n",
      "A2: The compendium was developed by ERM and sponsored by the American Petroleum Institute (API), with leadership and direction by Marcus Koblitz, Corporate Policy.\n",
      "\n",
      "Q3: What is the scope of the compendium in terms of industry coverage?\n",
      "A3: The compendium specifically focuses on the natural gas and oil industry, covering emissions methodologies relevant to this sector.\n",
      "\n",
      "Q4: How can companies in the natural gas and oil industry benefit from using this compendium?\n",
      "A4: Companies can use the compendium to ensure accurate and consistent GHG emissions reporting, meeting regulatory obligations and stakeholder expectations.\n",
      "\n",
      "Q5: Are there any specific regulatory obligations that companies in the natural gas and oil industry need to consider when reporting GHG emissions?\n",
      "A5: Yes, companies must comply with international and national reporting frameworks, such as the Greenhouse Gas Protocol and country-specific regulations, which may require accurate and transparent GHG emissions reporting.\n",
      "\n",
      "Q6: What are some of the key challenges companies in the natural gas and oil industry face when reporting GHG emissions?\n",
      "A6: Challenges may include data quality issues, emissions calculation complexities, and ensuring consistency across operations and reporting frameworks.\n",
      "\n",
      "Q7: How can companies ensure the accuracy and completeness of their GHG emissions reporting?\n",
      "A7: Companies can use the compendium to identify best practices, follow recommended methodologies, and engage with experts to ensure accurate and complete GHG emissions reporting.\n",
      "\n",
      "Q8: Are there any specific international reporting frameworks that companies in the natural gas and oil industry should consider when reporting GHG emissions?\n",
      "A8: Yes, companies should consider reporting frameworks such as the GHG Protocol, CDP, and international agreements like the Paris Agreement, which provide guidance on GHG emissions reporting.\n"
     ]
    }
   ],
   "source": [
    "from groq import Client\n",
    "import os\n",
    "\n",
    "# Set API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "groq_client = Client(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Build context from all chunks (filtered to stay under 4000 tokens)\n",
    "chunk_column = \"document\" if \"document\" in chunk_text.columns else chunk_text.columns[0]\n",
    "chunks = chunk_text[chunk_column].dropna().astype(str).tolist()\n",
    "\n",
    "# Keep appending chunks until reaching character limit (~16,000 chars = ~4k tokens)\n",
    "max_chars = 16000\n",
    "selected_chunks = []\n",
    "current_len = 0\n",
    "\n",
    "for c in chunks:\n",
    "    if current_len + len(c) > max_chars:\n",
    "        break\n",
    "    selected_chunks.append(c)\n",
    "    current_len += len(c)\n",
    "\n",
    "filtered_context = \"\\n---\\n\".join(selected_chunks)\n",
    "\n",
    "# Prompt\n",
    "prompt = f\"\"\"\n",
    "You are a GHG emissions consultant and expert in international and Australian climate reporting frameworks.\n",
    "\n",
    "Using the full context below, generate a list of **question and answer (Q&A) pairs** that summarize key insights, regulatory obligations, and challenges for companies.\n",
    "\n",
    "Context:\n",
    "{filtered_context}\n",
    "\n",
    "Format the output like this:\n",
    "Q1: ...\n",
    "A1: ...\n",
    "Q2: ...\n",
    "A2: ...\n",
    "(...continue...)\n",
    "\n",
    "Only include the questionâ€“answer pairs in your response.\n",
    "\n",
    "Begin:\n",
    "\"\"\"\n",
    "\n",
    "# Query Groq\n",
    "chat_completion = groq_client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a knowledgeable climate consultant generating clear and accurate Q&A pairs.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Show result\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(\"ðŸ§  Generated Q&A Pairs:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5115db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
